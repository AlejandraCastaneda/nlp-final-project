{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary libraries to use BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to set up the dataset so that it can be used with a TensorFlow model (i.e. BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/rorybeals/Desktop/CS159/nlp-final-project-1/data/liar.data/train.tsv\", \"r\") as infile, open(\"/Users/rorybeals/Desktop/CS159/nlp-final-project-1/data/liar.data/traincleaned.tsv\", \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        # Remove problematic quotes and extra line breaks\n",
    "        clean_line = line.replace('\"', '').replace('\\n', '').replace('\\r', '')\n",
    "        outfile.write(clean_line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tsv_line(line):\n",
    "    # Define the column types\n",
    "    column_defaults = [\n",
    "    '',  # JSON file name\n",
    "    '',  # Boolean flag as string\n",
    "    '',  # Statement\n",
    "    '',  # Topic\n",
    "    '',  # Speaker\n",
    "    '',  # Speaker's title\n",
    "    '',  # State\n",
    "    '',  # Party\n",
    "    0,   # Truth count 1\n",
    "    0,   # Truth count 2\n",
    "    0,   # Truth count 3\n",
    "    0,   # Truth count 4\n",
    "    0,   # Truth count 5\n",
    "    ''   # Source\n",
    "]\n",
    "    # Decode the line into individual columns\n",
    "    columns = tf.io.decode_csv(line, record_defaults=column_defaults, field_delim='\\t', use_quote_delim=True)\n",
    "    # Separate features and label\n",
    "    # Separate features and label (assuming no label for now)\n",
    "    string_features = columns[2:8] + columns[-1:]  # Select all string columns\n",
    "    numeric_features = columns[8:-1]  # Select integer columns (truth counts)\n",
    "\n",
    "    # Combine string and numeric features into a single dictionary\n",
    "    features = {\n",
    "        \"string_features\": string_features,\n",
    "        \"numeric_features\": tf.stack(numeric_features)\n",
    "    }\n",
    "\n",
    "    # If there's a label column, define it here; otherwise, return features only\n",
    "    label = columns[1]  # Replace with actual label column index if applicable\n",
    "    return features, label\n",
    "\n",
    "def create_tsv_dataset(file_path, batch_size=32):\n",
    "    # Load the file\n",
    "    dataset = tf.data.TextLineDataset(file_path)\n",
    "    # Skip the header if the file has one\n",
    "    # dataset = dataset.skip(1) <- curret file doesn't have a header but if it did we could skip the top row\n",
    "    # Parse each line\n",
    "    dataset = dataset.map(parse_tsv_line)\n",
    "    # Shuffle, batch, and prefetch for performance\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: {'string_features': <tf.Tensor: shape=(32, 7), dtype=string, numpy=\n",
      "array([[b'On how money from a possible lease of the Ohio Turnpike would be used',\n",
      "        b'infrastructure,transportation', b'john-kasich',\n",
      "        b'Governor of Ohio as of Jan. 10, 2011', b'Ohio', b'republican',\n",
      "        b'an interview'],\n",
      "       [b'Most of, if not all of, the [DeKalb school construction] projects always came in on or were under budget.',\n",
      "        b'education', b'thomas-brown', b'', b'Georgia', b'democrat',\n",
      "        b'an interview'],\n",
      "       [b'More than 9,000 Rhode Island voters used the Moderate Party master lever mechanism and they didnt have a single Moderate on their ballot.',\n",
      "        b'elections', b'kenneth-block', b'businessman', b'',\n",
      "        b'republican', b'a television interview'],\n",
      "       [b'The hour of sleep you lose during the change to daylight saving time might initially pose some health risks.',\n",
      "        b'science', b'joel-keehn', b'', b'', b'none', b'a blog'],\n",
      "       [b'Secretary Clinton changes her position on (gun issues) every election year, it seems, having one position in 2000 and then campaigning against President Obama and saying we dont need federal standards.',\n",
      "        b'candidates-biography,guns', b'martin-omalley',\n",
      "        b'Maryland governor', b'Maryland', b'democrat',\n",
      "        b'the Dec. 19 Democratic presidential debate'],\n",
      "       [b'U.S. police killed more people in just one month than the U.K.s did in over a century.',\n",
      "        b'guns', b'addicting-information', b'', b'', b'democrat',\n",
      "        b'an infographic on the Addicting Info website'],\n",
      "       [b'Roy Coopers refusal to do his job is costing taxpayers money.',\n",
      "        b'ethics,legal-issues,public-service,states', b'pat-mccrory',\n",
      "        b'Governor of North Carolina', b'North Carolina', b'republican',\n",
      "        b'a press release'],\n",
      "       [b'Health care reform legislation is likely to mandate free sex change surgeries.',\n",
      "        b'health-care', b'blog-posting', b'', b'', b'none',\n",
      "        b'a news release'],\n",
      "       [b'Says Barack Obama is apparently not for vetting people and saying just anybody can come to the United States.',\n",
      "        b'homeland-security,terrorism', b'glenn-grothman',\n",
      "        b'State Senator, 20th District', b'Wisconsin', b'republican',\n",
      "        b'a radio interview'],\n",
      "       [b'The Family Research Council, according to some government agencies, is a terrorist group.',\n",
      "        b'terrorism', b'ben-carson', b'', b'', b'republican',\n",
      "        b'an interview on CNN'],\n",
      "       [b'Says 11 soccer players on the U.S. Mens National Team are immigrants.',\n",
      "        b'immigration,sports', b'nancy-pelosi', b'House Minority Leader',\n",
      "        b'California', b'democrat', b'a tweet'],\n",
      "       [b'Says Hillary Clinton said the Veterans Affairs scandal is over-exaggerated. She said she was satisfied with what was going on.',\n",
      "        b'veterans', b'donald-trump', b'President-Elect', b'New York',\n",
      "        b'republican', b'the NBC Commander-In-Chief Forum '],\n",
      "       [b'Texas this fiscal year will have more money in reserve than the other 49 states combined.',\n",
      "        b'state-budget,state-finances,states', b'dan-patrick',\n",
      "        b'Lieutenant governor-elect', b'Texas', b'republican',\n",
      "        b'an interview on KLBJ AM in Austin'],\n",
      "       [b'Says Alex Sink failed Florida homeowners by using predatory lending practices.',\n",
      "        b'corporations', b'republican-party-florida', b'', b'',\n",
      "        b'republican', b'a YouTube video'],\n",
      "       [b'We now have driven (health care) costs down to the lowest theyve been in 50 years.',\n",
      "        b'health-care', b'hillary-clinton', b'Presidential candidate',\n",
      "        b'New York', b'democrat',\n",
      "        b'comments during the South Carolina Democratic presidential debate'],\n",
      "       [b'In Rick Perrys Texas, we import nurses ... from other countries.',\n",
      "        b'health-care', b'bill-white', b'Former mayor of Houston',\n",
      "        b'Texas', b'democrat',\n",
      "        b'a speech at the Texas Democratic Party convention'],\n",
      "       [b'AARP is the largest reseller of insurance in the country and has a vested interest in seeing that the market for reselling supplemental insurance expands.',\n",
      "        b'health-care,legal-issues,medicare', b'ginny-brown-waite',\n",
      "        b'Congresswoman', b'Florida', b'republican', b'a letter to AARP'],\n",
      "       [b'We admit about 100,000 permanent immigrants from the Middle East every year.',\n",
      "        b'immigration', b'donald-trump', b'President-Elect', b'New York',\n",
      "        b'republican', b'a speech in Youngstown, Ohio'],\n",
      "       [b'Climate change is directly related to the growth of terrorism.',\n",
      "        b'climate-change,terrorism', b'bernie-s', b'U.S. Senator',\n",
      "        b'Vermont', b'independent',\n",
      "        b'a Democratic presidential debate in Des Moines, Iowa.'],\n",
      "       [b'Says veterans disability claims backlog doubled in Obamas first term.',\n",
      "        b'veterans', b'john-cornyn', b'Senator', b'Texas', b'republican',\n",
      "        b'a tweet'],\n",
      "       [b'For every $1 spent on afterschool programs, we can save over $5, almost $6, in crime costs down the line.',\n",
      "        b'crime,economy,education,poverty', b'peter-kilmartin',\n",
      "        b'state representative', b'Rhode Island', b'democrat',\n",
      "        b'a speech at the state Democratic convention'],\n",
      "       [b'Gov. Scott Walker bought 80 new, brand-new vehicles for the state that we probably dont need.',\n",
      "        b'government-efficiency,state-budget,state-finances,transportation',\n",
      "        b'kathleen-vinehout', b'', b'', b'democrat', b'a meeting'],\n",
      "       [b'On whether the United States should intervene in Libya.',\n",
      "        b'foreign-policy,military', b'newt-gingrich',\n",
      "        b\"Co-host on CNN's Crossfire\", b'Georgia', b'republican',\n",
      "        b'televised interviews'],\n",
      "       [b'(John McCain) was even mentioned as a running mate with John Kerry.',\n",
      "        b'elections', b'citizens-united-political-victory-fund', b'',\n",
      "        b'Washington, D.C.', b'republican', b'a TV ad'],\n",
      "       [b'When asked about equal pay for women, (Rubios) quote was that it was a waste of time.',\n",
      "        b'labor,women', b'patrick-murphy', b'', b'Florida', b'democrat',\n",
      "        b'a U.S. Senate debate'],\n",
      "       [b'Over the last few years, weve put more people back to work than all the other advanced economies combined.',\n",
      "        b'economy,jobs,labor,workers', b'barack-obama', b'President',\n",
      "        b'Illinois', b'democrat',\n",
      "        b'a press conference after the G20 summit'],\n",
      "       [b\"Scott Maddox has run losing campaigns for 3 of Florida's 4 available cabinet positions.\",\n",
      "        b'agriculture,candidates-biography', b'adam-putnam',\n",
      "        b'Florida Commissioner of Agriculture', b'Florida',\n",
      "        b'republican', b'a campaign statement'],\n",
      "       [b'Recent international reports show the United States near the bottom among industrialized nations for k-12 academic achievement.',\n",
      "        b'education', b'chip-rogers', b'State Senator', b'Georgia',\n",
      "        b'republican', b'a town hall meeting'],\n",
      "       [b'There is a federal criminal law that says its a crime to transport dentures across state lines.',\n",
      "        b'public-health', b'bob-goodlatte', b'U.S. Congressman',\n",
      "        b'Virginia', b'republican', b'a radio interview.'],\n",
      "       [b'Look at the debt that has been accumulated in the last two years. Its more debt under this president than all those other presidents combined.',\n",
      "        b'deficit,federal-budget,history', b'sarah-palin', b'',\n",
      "        b'Alaska', b'republican',\n",
      "        b\"an interview with Fox News' Greta Van Susteren\"],\n",
      "       [b'We have been in Afghanistan longer now than we have been in any foreign land conducting a war in our nations history.',\n",
      "        b'afghanistan', b'robert-gibbs',\n",
      "        b'Former White House Press Secretary', b'', b'democrat',\n",
      "        b\"an interview on NBC's Meet the Press\"],\n",
      "       [b'President Reagan did it (raised the debt ceiling) 18 times. George W. Bush did it seven times.',\n",
      "        b'bipartisanship,federal-budget', b'barack-obama', b'President',\n",
      "        b'Illinois', b'democrat', b'a televised address']], dtype=object)>, 'numeric_features': <tf.Tensor: shape=(32, 5), dtype=int32, numpy=\n",
      "array([[  9,   8,  10,  18,   3],\n",
      "       [  0,   0,   0,   1,   0],\n",
      "       [  0,   3,   2,   3,   0],\n",
      "       [  0,   0,   0,   0,   0],\n",
      "       [  3,   1,  10,   4,   0],\n",
      "       [  0,   1,   0,   0,   0],\n",
      "       [  5,   2,   3,   0,   1],\n",
      "       [  7,  19,   3,   5,  44],\n",
      "       [  2,   4,   1,   1,   0],\n",
      "       [  7,  12,   3,   2,   4],\n",
      "       [  3,   7,  11,   2,   3],\n",
      "       [ 63, 114,  51,  37,  61],\n",
      "       [  4,   4,   3,   4,   4],\n",
      "       [ 10,   6,   6,   6,   4],\n",
      "       [ 40,  29,  69,  76,   7],\n",
      "       [  2,   3,   5,   7,   3],\n",
      "       [  2,   0,   2,   0,   0],\n",
      "       [ 63, 114,  51,  37,  61],\n",
      "       [ 18,  12,  22,  41,   0],\n",
      "       [  5,   3,   6,   2,   1],\n",
      "       [  0,   0,   2,   1,   1],\n",
      "       [  1,   1,   1,   1,   0],\n",
      "       [ 16,  15,  20,  10,  11],\n",
      "       [  0,   0,   0,   1,   0],\n",
      "       [  2,   1,   4,   5,   0],\n",
      "       [ 70,  71, 160, 163,   9],\n",
      "       [  0,   1,   1,   2,   1],\n",
      "       [  1,   0,   1,   1,   0],\n",
      "       [  0,   1,   4,   3,   0],\n",
      "       [  9,  19,   9,   6,   6],\n",
      "       [  1,   1,   0,   1,   0],\n",
      "       [ 70,  71, 160, 163,   9]], dtype=int32)>}\n",
      "Labels: tf.Tensor(\n",
      "[b'half-true' b'mostly-true' b'mostly-true' b'true' b'half-true' b'false'\n",
      " b'barely-true' b'false' b'false' b'false' b'false' b'barely-true'\n",
      " b'pants-fire' b'false' b'false' b'half-true' b'half-true' b'mostly-true'\n",
      " b'barely-true' b'true' b'half-true' b'barely-true' b'false' b'true'\n",
      " b'half-true' b'half-true' b'false' b'half-true' b'mostly-true' b'false'\n",
      " b'mostly-true' b'true'], shape=(32,), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 22:18:40.444018: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Path to your .tsv file\n",
    "file_path = \"/Users/rorybeals/Desktop/CS159/nlp-final-project-1/data/liar.data/traincleaned.tsv\"\n",
    "\n",
    "# Create the dataset\n",
    "batch_size = 32\n",
    "\n",
    "dataset = create_tsv_dataset(file_path, batch_size)\n",
    "\n",
    "# Iterate through the dataset\n",
    "for features, labels in dataset.take(1):\n",
    "    print(\"Features:\", features)\n",
    "    print(\"Labels:\", labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize pandas to get some preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common label: republican\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file into a pandas DataFrame\n",
    "file_path = \"/Users/rorybeals/Desktop/CS159/nlp-final-project-1/data/liar.data/train.tsv\"\n",
    "column_names = [\n",
    "    \"json_file\", \"label\", \"statement\", \"topic\", \"speaker\", \"speaker_title\",\n",
    "    \"state\", \"party\", \"barely_true\", \"false\", \"half_true\",\n",
    "    \"mostly_true\", \"pants_on_fire\", \"source\"\n",
    "]\n",
    "df = pd.read_csv(file_path, sep='\\t', names=column_names)\n",
    "\n",
    "# Find the most common label\n",
    "most_common_label = df['party'].value_counts().idxmax()\n",
    "print(\"Most common label:\", most_common_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'idmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m4/74vppbc12tv4dpy3k6tl3yhc0000gn/T/ipykernel_1251/308508475.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;31m# Group by label and compute the mean of truth_count_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maverage_truth_count_5_per_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pants_on_fire'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Truth Count 5 per label:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_truth_count_5_per_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'idmax'"
     ]
    }
   ],
   "source": [
    "# Group by label and compute the mean of truth_count_5\n",
    "average_truth_count_5_per_label = df.groupby('state')['pants_on_fire'].mean()\n",
    "print(\"Average Truth Count 5 per label:\")\n",
    "print(average_truth_count_5_per_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 states by label:\n",
      "          label         state  count\n",
      "0   barely-true         Texas    192\n",
      "1   barely-true       Florida    188\n",
      "2   barely-true     Wisconsin    122\n",
      "3   barely-true      New York     98\n",
      "4   barely-true      Virginia     68\n",
      "5         false         Texas    188\n",
      "6         false     Wisconsin    171\n",
      "7         false       Florida    167\n",
      "8         false      New York    166\n",
      "9         false      Virginia     95\n",
      "10    half-true       Florida    224\n",
      "11    half-true         Texas    198\n",
      "12    half-true     Wisconsin    147\n",
      "13    half-true      Illinois    137\n",
      "14    half-true      New York    121\n",
      "15  mostly-true       Florida    217\n",
      "16  mostly-true         Texas    182\n",
      "17  mostly-true      Illinois    149\n",
      "18  mostly-true     Wisconsin    133\n",
      "19  mostly-true      New York    118\n",
      "20   pants-fire         Texas     87\n",
      "21   pants-fire      New York     66\n",
      "22   pants-fire     Wisconsin     57\n",
      "23   pants-fire       Florida     45\n",
      "24   pants-fire  Rhode Island     30\n",
      "25         true         Texas    162\n",
      "26         true       Florida    156\n",
      "27         true          Ohio    128\n",
      "28         true      Illinois    111\n",
      "29         true      New York     88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/74vppbc12tv4dpy3k6tl3yhc0000gn/T/ipykernel_1251/3401135852.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_5_states_by_label = state_counts.groupby('label').apply(\n"
     ]
    }
   ],
   "source": [
    "# Group by label and state, and count occurrences\n",
    "state_counts = df.groupby(['label', 'state']).size().reset_index(name='count')\n",
    "\n",
    "# For each label, find the top 5 states\n",
    "top_5_states_by_label = state_counts.groupby('label').apply(\n",
    "    lambda group: group.nlargest(5, 'count')\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Top 5 states by label:\")\n",
    "print(top_5_states_by_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16a04d8a27fb2f97974c9346e1eac40ed1183433b83541b67d4d879c08daf4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
